{"nbformat_minor":4,"nbformat":4,"cells":[{"source":["# Deep Learning &mdash; Assignment 3"],"cell_type":"markdown","metadata":{}},{"source":["Third assignment for the 2020 Deep Learning course (NWI-IMC058) of the Radboud University.\n","\n","_Gijs van Tulder (g.vantulder@cs.ru.nl) and Twan van Laarhoven (tvanlaarhoven@cs.ru.nl)_\n","\n","_September 2020_"],"cell_type":"markdown","metadata":{}},{"source":["-----\n","\n","**Names:**\n","\n","**Group:**\n","\n","-----"],"cell_type":"markdown","metadata":{}},{"source":["**Instructions:**\n","* Fill in your names and the name of your group.\n","* Answer the questions and complete the code where necessary.\n","* Re-run the whole notebook before you submit your work.\n","* Save the notebook as a PDF and submit that in Brightspace together with the `.ipynb` notebook file.\n","* The easiest way to make a PDF of your notebook is via File > Print Preview and then use your browser's print option to print to PDF."],"cell_type":"markdown","metadata":{}},{"source":["## Objectives\n","\n","In this assignment you will\n","1. Implement an LSTM module from scratch.\n","2. Use the built-in LSTM module from PyTorch.\n","3. Compare fully connected and recurrent neural networks in an experiment.\n","4. Experiment with data augmentation."],"cell_type":"markdown","metadata":{}},{"source":["## Required software\n","\n","If you haven't done so already, you will need to install the following additional libraries:\n","* `torch` and `torchvision` for PyTorch,\n","* `d2l`, the library that comes with [Dive into deep learning](https://d2l.ai) book.\n","\n","All libraries can be installed with `pip install`."],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["%matplotlib inline\n","import csv\n","import glob\n","import re\n","import numpy as np\n","import scipy.io\n","import scipy.signal\n","import matplotlib.pyplot as plt\n","import torch\n","from d2l import torch as d2l"],"outputs":[],"metadata":{}},{"source":["## 3.1 Dataset: Atrial fibrillation classification on ECG recordings\n","\n","In this assignment we will work with data from the [PhysioNet Computing in Cardiology Challenge 2017](https://physionet.org/content/challenge-2017/1.0.0/) to classify atrial fibrillation in electrocardiograms (ECGs). Atrial fibrillation is an abnormal heart rhythm, which can be recognized as irregular patterns in ECG recordings.\n","\n","**Download the [training dataset](https://physionet.org/files/challenge-2017/1.0.0/training2017.zip) from the challenge website and extract the files.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["# !mkdir -p data\n","# !wget -c -O data/training2017.zip https://physionet.org/files/challenge-2017/1.0.0/training2017.zip\n","# !cd data/ ; unzip -qo training2017.zip"],"outputs":[],"metadata":{}},{"source":["The dataset consists of a number of recordings and corresponding labels. We use a subset of the dataset that includes only the samples with a normal rhythm (label N or class 0) and those with atrial fibrillation (label A or class 1).\n","\n","**Run the code to load the data.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["class ECGDataset(torch.utils.data.Dataset):\n","    # labels: 'N', 'A', 'O'\n","    def __init__(self, directory, max_length=18286, class_labels=('N', 'A', 'O')):\n","        super().__init__()\n","        self.class_labels = class_labels\n","        self.load_data(directory, max_length)\n","\n","    def load_data(self, directory, max_length):\n","        label_map = {}\n","        with open('%s/REFERENCE.csv' % directory, 'r') as f:\n","            for line in csv.reader(f):\n","                label_map[line[0]] = line[1]\n","\n","        samples = []\n","        lengths = []\n","        labels = []\n","\n","        for file in sorted(glob.glob('%s/*.mat' % directory)):\n","            subject_id = re.match('.+(A[0-9]+)\\.mat', file)[1]\n","            label = label_map[subject_id]\n","            if label not in self.class_labels:\n","                # skip this label\n","                continue\n","            mat_data = scipy.io.loadmat(file)\n","            sample = mat_data['val'][0]\n","            if len(sample) < 4000:\n","                # skip short samples\n","                continue\n","            samples.append(np.pad(sample, (0, max_length - len(sample))))\n","            lengths.append(len(sample))\n","            labels.append(self.class_labels.index(label_map[subject_id]))\n","\n","        # concatenate\n","        samples = np.vstack(samples)\n","        lengths = np.stack(lengths)\n","        labels = np.stack(labels)\n","        \n","        # convert to PyTorch tensors\n","        self.samples = torch.tensor(samples, dtype=torch.float32)\n","        self.lengths = torch.tensor(lengths, dtype=torch.long)\n","        self.labels = torch.tensor(labels, dtype=torch.long)\n","\n","    @property\n","    def class_proportions(self):\n","        return torch.mean((torch.arange(len(self.class_labels))[None, :] ==\n","                           self.labels[:, None]).to(torch.float), axis=0)\n","        \n","    def __getitem__(self, index):\n","        l = self.lengths[index]\n","        x = self.samples[index, :l]\n","        y = self.labels[index]\n","        return x, y\n","\n","    def __len__(self):\n","        return self.samples.shape[0]\n","\n","\n","data = ECGDataset('data/training2017', class_labels=('N', 'A'))"],"outputs":[],"metadata":{}},{"source":["The recordings have different lengths (between 30 to 60 seconds). There are more \"normal\" recordings than recordings that show atrial fibrillation.\n","\n","**Print some statistics of the data.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["print('Number of examples: %d' % len(data))\n","print()\n","print('Minimum length: %d' % torch.min(data.lengths))\n","print('Median length:  %d' % torch.median(data.lengths))\n","print('Maximum length: %d' % torch.max(data.lengths))\n","print()\n","print('Class distribution:', data.class_proportions.numpy())"],"outputs":[],"metadata":{}},{"source":["Each example has a 1D vector that represents the ECG measurement over time.\n","\n","**Run the code to plot two recordings from each class.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["plt.figure(figsize=(12, 5))\n","for i, idx in enumerate([0, 3, 1, 4]):\n","    x, y = data[idx]\n","    plt.subplot(2, 2, i + 1)\n","    plt.plot(x)\n","    plt.title('Label: %s' % data.class_labels[y])\n","    plt.xlim(3000, 5000)\n","    plt.ylabel('Amplitude (mV)')\n","plt.tight_layout()"],"outputs":[],"metadata":{}},{"source":["**The class distribution in this dataset is quite unbalanced. What consequences could this have?**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here."],"cell_type":"markdown","metadata":{}},{"source":["## 3.2 Feature extraction\n","\n","To simplify our poblem a bit, we will convert the 1D ECG signals to [spectrograms](https://en.wikipedia.org/wiki/Spectrogram). A spectrogram is a summary of the frequencies in small windows of the recording. These features will make it easier to train a classification model.\n","\n","**Run the code to compute the spectrograms.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["class ECGSpectrumDataset(ECGDataset):\n","    NPERSEG = 32\n","    NOVERLAP = 32 // 8\n","    \n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.compute_spectrum()\n","    \n","    def compute_spectrum(self):\n","        f, t, Sxx = scipy.signal.spectrogram(self.samples.numpy(), scaling='spectrum',\n","                                             nperseg=self.NPERSEG, noverlap=self.NOVERLAP)\n","        # normalize the measurements for each frequency\n","        Sxx = Sxx - np.mean(Sxx, axis=(0, 2), keepdims=True)\n","        Sxx = Sxx / np.std(Sxx, axis=(0, 2), keepdims=True)\n","        self.samples = torch.tensor(Sxx.transpose(0, 2, 1))\n","        self.lengths = (self.lengths - self.NPERSEG) // (self.NPERSEG - self.NOVERLAP)\n","\n","data_spectrum = ECGSpectrumDataset('data/training2017', class_labels=('N', 'A'))  "],"outputs":[],"metadata":{}},{"source":["**Plot the spectrograms for the four samples from the previous plot.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["plt.figure(figsize=(12, 5))\n","for i, idx in enumerate([0, 3, 1, 4]):\n","    x, y = data_spectrum[idx]\n","    plt.subplot(2, 2, i + 1)\n","    plt.imshow(x.T)\n","    plt.title('Label: %s' % data.class_labels[y])\n","    # show roughly the same segments as in the previous plot\n","    plt.xlim(3000 // 28, 5000 // 28)\n","    plt.ylabel('Amplitude (mV)')\n","plt.tight_layout()"],"outputs":[],"metadata":{}},{"source":["The spectrogram data has 17 frequency bins for each window. We will use these as our input features. We normalized the data for each frequency to zero mean, unit variance.\n","\n","**Print the statistics of the spectrum dataset and check the shape of the first sample.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["print('Minimum length: %d' % torch.min(data_spectrum.lengths))\n","print('Median length:  %d' % torch.median(data_spectrum.lengths))\n","print('Maximum length: %d' % torch.max(data_spectrum.lengths))\n","print()\n","print('Mean value:         %f' % torch.mean(data_spectrum.samples))\n","print('Standard deviation: %f' % torch.std(data_spectrum.samples))\n","print()\n","# print the shape of the first sample\n","x, y = data_spectrum[0]\n","print('Shape of first sample:', x.shape)"],"outputs":[],"metadata":{}},{"source":["## 3.3 Splitting training and validation sets\n","\n","We will split our dataset in separate training and validation sets (80% &ndash; 20%).\n","\n","**Run the code to create a random split.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["train_samples = int(0.8 * len(data))\n","val_samples = len(data) - train_samples\n","data_train, data_val = torch.utils.data.random_split(data_spectrum, (train_samples, val_samples))\n","\n","print('data_train:', len(data_train))\n","print('data_val:  ', len(data_val))"],"outputs":[],"metadata":{}},{"source":["## 3.4 Creating a balanced dataset by resampling\n","\n","As you have seen, the dataset contains far more normal recordings than recordings with atrial fibrillation. We will create a balanced dataset by including multiple copies of the atrial fibrillation samples.\n","\n","In this assignment we will also use a balanced validation set. This is something you may or may not want to do in practice, because it means that your validation set is no longer representative of the test data. The advantage is that the accuracy on a balanced validation set is easier to compare with the accuracy on the training set.\n","\n","**Run the code to create balanced training and validation sets.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["def balance_dataset(dataset):\n","    # collect labels from the source dataset\n","    labels = torch.zeros((len(dataset),), dtype=torch.long)\n","    for i, (x, y) in enumerate(dataset):\n","        labels[i] = y\n","    indices = torch.arange(len(dataset), dtype=torch.long)\n","\n","    unique_labels = np.unique(labels.numpy())\n","    \n","    # resample for minority classes\n","    n = [torch.sum((labels == label).to(torch.long)).item()\n","         for label in unique_labels]\n","    \n","    if len(np.unique(n)) == 1:\n","        return dataset\n","    \n","    print('Samples per class:', n)\n","    for i, label in enumerate(unique_labels):\n","        while n[i] < max(n):\n","            extra_samples = max(n) - n[i]\n","            print('Repeating %d samples for class %d' % (extra_samples, label))\n","\n","            # take a random subset of samples from this class\n","            idxs = torch.where(labels == label)[0].numpy()\n","            np.random.shuffle(idxs)\n","            idxs = torch.tensor(idxs[:extra_samples], dtype=torch.long)\n","\n","            # add these indices to the list\n","            indices = torch.cat((indices, idxs))\n","            n[i] += len(idxs)\n","    \n","    return torch.utils.data.Subset(dataset, indices)\n","\n","data_train = balance_dataset(data_train)\n","data_val   = balance_dataset(data_val)"],"outputs":[],"metadata":{}},{"source":["## 3.5 Splitting recordings into chunks\n","\n","The recordings in our dataset all have different lengths and are generally quite long. To simplify training, we will split them into smaller chunks of 40 time steps each. This means that each recording will have multiple chunks in the dataset.\n","\n","**Run the code to create the pre-chunked dataset.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["class ChunkedDataset(torch.utils.data.TensorDataset):\n","    def __init__(self, source_dataset, chunk_size=40):\n","        super().__init__()\n","        self.make_chunks(source_dataset, chunk_size)\n","    \n","    def make_chunks(self, source_dataset, chunk_size):\n","        all_x, all_y = [], []\n","        for x, y in source_dataset:\n","            for chunk in range(x.shape[0] // chunk_size):\n","                offset = chunk * chunk_size\n","                all_x.append(x[offset:offset + chunk_size])\n","                all_y.append(y)\n","        self.tensors = (torch.stack(all_x), torch.tensor(all_y))\n","\n","chunked_data_train = ChunkedDataset(data_train)\n","chunked_data_val = ChunkedDataset(data_val)\n","\n","# rebalance to compensate for any differences in length\n","chunked_data_train = balance_dataset(chunked_data_train)\n","chunked_data_val   = balance_dataset(chunked_data_val)\n","\n","print('chunked_data_train:', len(chunked_data_train))\n","print('chunked_data_val:  ', len(chunked_data_val))"],"outputs":[],"metadata":{}},{"source":["## 3.6 Preparing data loaders\n","\n","As in the previous assignment, we will use the PyTorch [DataLoader](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader) class to divide our datasets in minibatches.\n","\n","**Run the code to create the data loaders. Look at the shape of the first minibatch.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["chunked_loaders = {\n","    'train': torch.utils.data.DataLoader(chunked_data_train, shuffle=True, batch_size=128),\n","    'val':   torch.utils.data.DataLoader(chunked_data_val, batch_size=128),\n","}\n","\n","# print the x and y shapes for one minibatch\n","for (x, y) in chunked_loaders['train']:\n","    print(x.shape, y.shape)\n","    break"],"outputs":[],"metadata":{}},{"source":["## 3.7 Implementing an LSTM\n","\n","Time series data such as the ECG recordings are a good target for recurrent neural networks (see [Section 8.4](http://d2l.ai/chapter_recurrent-neural-networks/rnn.html#recurrent-networks-with-hidden-states) of the D2L book).\n","\n","The class below implements an RNN layer in PyTorch, using the equations discussed in [section 8.4.2](http://d2l.ai/chapter_recurrent-neural-networks/rnn.html#recurrent-networks-with-hidden-states) of the book.\n","\n","**Read through the code to see how the RNN works.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["class RNN(torch.nn.Module):\n","    \"\"\"RNN module.\n","    \n","    This implements an RNN module as discussed in Section 8.4 of the D2L book\n","    (http://d2l.ai/chapter_recurrent-neural-networks/rnn.html).\n","\n","    Note that our implementation is slightly different from that in the book.\n","    The book also implements a linear output layer on top of the RNN, but this\n","    is not really part of the standard RNN or LSTM definitions.\n","\n","    Our implementation only has the hidden units of the RNN, which are used as\n","    the output of the layer. You can then implement a separate torch.nn.Linear\n","    layer on top of the output of this module, if you want.\n","    \n","    Parameters:\n","       num_inputs:  scalar, the number of inputs to this module\n","       num_hiddens: scalar, the number of hidden units\n","    \n","    Input and output: see the forward function.\n","    \"\"\"\n","    # see d2l.ai 8.5\n","    def __init__(self, num_inputs, num_hiddens):\n","        super().__init__()\n","        self.num_inputs = num_inputs\n","        self.num_hiddens = num_hiddens\n","        self.initialize_parameters()\n","\n","    def initialize_parameters(self):\n","        \"\"\"Initializes the parameters of the RNN module.\n","        \n","        This initializes the bias vector b_h and weight matrices W_xh and W_hh.\n","        \"\"\"\n","        def three():\n","            return (torch.nn.Parameter(torch.normal(0, 0.01, size=(self.num_inputs, self.num_hiddens))),\n","                    torch.nn.Parameter(torch.normal(0, 0.01, size=(self.num_hiddens, self.num_hiddens))),\n","                    torch.nn.Parameter(torch.zeros(size=(self.num_hiddens,))))\n","\n","        # parameters for the rnn\n","        self.W_xh, self.W_hh, self.b_h = three()\n","\n","    def forward(self, inputs):\n","        \"\"\"Computes the forward pass of the RNN module.\n","        \n","        Input:\n","           inputs:  a tensor of shape (samples, steps, input features)\n","                    giving the input for each sample at each step\n","        \n","        Output:\n","           outputs: a tensor of shape (samples, steps, hidden features)\n","                    providing the hidden values at the end of each step\n","           state:   a tuple (hiddens,)\n","                    the state of the RNN at the end of the last step,\n","                    with hiddens a tensor of shape (samples, hidden_features)\n","        \"\"\"\n","        batch_size = inputs.shape[0]\n","\n","        # initialize state\n","        state = (torch.zeros(size=(batch_size, self.num_hiddens),\n","                             dtype=inputs.dtype, device=inputs.device),)\n","\n","        # run steps\n","        outputs = []\n","        for step in range(inputs.shape[1]):\n","            state = self.one_step(inputs[:, step], state)\n","            outputs.append(state[0])\n","\n","        # concatenate outputs\n","        outputs = torch.stack(outputs, axis=1)\n","        return outputs, state\n","\n","    def one_step(self, x, state):\n","        \"\"\"Run a single step of the RNN module.\n","        \n","        Input:\n","           x:     a tensor of shape (samples, input features)\n","                  giving the input for each sample at the current step\n","           state: a tuple (hiddens,)\n","                  the state of the RNN at the end of the previous step,\n","                  with hiddens a tensor of shape (samples, hidden_features)\n","        \"\"\"\n","        # extract current state\n","        (h,) = state\n","\n","        # see http://d2l.ai/chapter_recurrent-neural-networks/rnn-scratch.html#rnn-model\n","\n","        # new hidden\n","        h = torch.tanh(torch.mm(x, self.W_xh) + torch.mm(h, self.W_hh) + self.b_h)\n","\n","        # return the state\n","        return (h,)\n","\n","    def __repr__(self):\n","        return ('RNN(num_inputs=%d, num_hiddens=%d)' %\n","                (self.num_inputs, self.num_hiddens))\n","\n","\n","# quick sanity check\n","rnn = RNN(3, 5)\n","print(rnn)\n","print('Parameters:', [name for name, _ in rnn.named_parameters()])"],"outputs":[],"metadata":{}},{"source":["The design of the LSTM module is more complex than that of the RNN, but it follows a similar pattern of looping over all steps in the input. You can use the RNN implementation as a basis for an LSTM module.\n","\n","**Implement the LSTM module below.**\n","\n","The equations and code in [Section 9.2](http://d2l.ai/chapter_recurrent-modern/lstm.html) can provide some inspiration. Be aware that the book uses mxnet, uses slightly different input shapes, and adds an additional output layer `y`, so you probably cannot copy code directly."],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["class LSTM(torch.nn.Module):\n","    def __init__(self, num_inputs, num_hiddens):\n","        super().__init__()\n","        self.num_inputs = num_inputs\n","        self.num_hiddens = num_hiddens\n","        self.initialize_parameters()\n","\n","    def initialize_parameters(self):\n","        # TODO initialize the LSTM weights\n","\n","    def forward(self, inputs):\n","        # TODO implement the forward pass of the LSTM\n","\n","    def __repr__(self):\n","        return ('LSTM(num_inputs=%d, num_hiddens=%d)' %\n","                (self.num_inputs, self.num_hiddens))\n","\n","\n","# quick sanity check\n","lstm = LSTM(3, 5)\n","print(lstm)\n","print('Parameters:', [name for name, _ in lstm.named_parameters()])"],"outputs":[],"metadata":{}},{"source":["## 3.8 Defining the training loop\n","\n","As last week, we need to define some functions to run the train the models.\n","\n","**Run the code to define the functions.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["def accuracy(y_hat, y):\n","    # Computes the mean accuracy.\n","    # y_hat: raw network output (before sigmoid or softmax)\n","    #        shape (samples, classes)\n","    # y:     shape (samples)\n","    if y_hat.shape[1] == 1:\n","        # binary classification\n","        y_hat = (y_hat[:, 0] > 0).to(y.dtype)\n","    else:\n","        # multi-class classification\n","        y_hat = torch.argmax(y_hat, axis=1).to(y.dtype)\n","    correct = (y_hat == y).to(torch.float32)\n","    return torch.mean(correct)"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["def train(net, data_loaders, epochs=100, lr=0.01, device=d2l.try_gpu()):\n","    # Trains the model net with data from the data_loaders['train'] and data_loaders['val'].\n","    net = net.to(device)\n","    \n","    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","\n","    animator = d2l.Animator(xlabel='epoch',\n","                            legend=['train loss', 'train acc', 'validation acc'],\n","                            figsize=(10, 5))\n","\n","    timer = {'train': d2l.Timer(), 'val': d2l.Timer()}\n","\n","    for epoch in range(epochs):\n","        # monitor loss, accuracy, number of samples\n","        metrics = {'train': d2l.Accumulator(3), 'val': d2l.Accumulator(3)}\n","\n","        for phase in ('train', 'val'):\n","            # switch network to train/eval mode\n","            net.train(phase == 'train')\n","\n","            for i, (x, y) in enumerate(data_loaders[phase]):\n","                timer[phase].start()\n","\n","                # move to device\n","                x = x.to(device)\n","                y = y.to(device)\n","\n","                # compute prediction\n","                y_hat = net(x)\n","                \n","                if y_hat.shape[1] == 1:\n","                    # compute binary cross-entropy loss\n","                    loss = torch.nn.BCEWithLogitsLoss()(y_hat[:, 0], y.to(torch.float))\n","                else:\n","                    # compute cross-entropy loss\n","                    loss = torch.nn.CrossEntropyLoss()(y_hat, y)\n","\n","                if phase == 'train':\n","                    # compute gradients and update weights\n","                    optimizer.zero_grad()\n","                    loss.backward()\n","                    optimizer.step()\n","\n","                metrics[phase].add(loss * x.shape[0],\n","                                   accuracy(y_hat, y) * x.shape[0],\n","                                   x.shape[0])\n","\n","                timer[phase].stop()\n","\n","        animator.add(epoch + 1,\n","            (metrics['train'][0] / metrics['train'][2],\n","             metrics['train'][1] / metrics['train'][2],\n","             metrics['val'][1] / metrics['val'][2]))\n","\n","    train_loss = metrics['train'][0] / metrics['train'][2]\n","    train_acc  = metrics['train'][1] / metrics['train'][2]\n","    val_acc    = metrics['val'][1] / metrics['val'][2]\n","    examples_per_sec = metrics['train'][2] * epochs / timer['train'].sum()\n","    \n","    print(f'train loss {train_loss:.3f}, train acc {train_acc:.3f}, '\n","          f'val acc {val_acc:.3f}')\n","    print(f'{examples_per_sec:.1f} examples/sec '\n","          f'on {str(device)}')"],"outputs":[],"metadata":{}},{"source":["## 3.9 Constructing some networks\n","\n","In the next experiments you will train different network architectures to see how they perform on the ECG dataset.\n","\n","The input to all networks has the shape (samples, time steps, features) = (mb_size, 40, 17). The output should be a single feature, shape (mb_size, 1), that will be used in a binary cross-entropy loss function. (The networks should not include the final sigmoid activation function.)\n","\n","Some simple baselines:\n","* `FullyConnectedNet`: A simple fully connected network that takes all features.\n","* `MeanSpectrumNet`: A fully connected network that works on the mean spectrum over all time steps.\n","\n","A convolutional network:\n","* `ConvNet`: This network does a convolution over the time steps, using the 17 input features as channels.\n","\n","Some recurrent models:\n","* `RNNNet`: A recurrent network with a simple RNN module.\n","* `LSTMNet`: A recurrent network with a more advanced LSTM module.\n","* `TorchLSTMNet`: The same model, but using the PyTorch implementation of the LSTM."],"cell_type":"markdown","metadata":{}},{"source":["### FullyConnectedNet\n","\n","**Check the implementation of the following baseline architecture:**\n","\n","* Linear layer: network inputs to 512 units followed by a ReLU.\n","* Linear layer: 512 to 256 units followed by a ReLU.\n","* Linear layer: 256 to the network output."],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["class FullyConnectedNet(torch.nn.Module):\n","    def __init__(self, inputs, outputs=1):\n","        super().__init__()\n","\n","        # by defining these layers here, they are included in the\n","        # parameters() list of this module, so they can be trained\n","        self.linear = torch.nn.Sequential(\n","            torch.nn.Flatten(),\n","            torch.nn.Linear(inputs, 512),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(512, 256),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(256, outputs)\n","        )\n","        \n","    def forward(self, x):\n","        # x shape: (samples, steps, inputs)\n","        return self.linear(x)\n","\n","net = FullyConnectedNet(40 * 17)\n","print(net)"],"outputs":[],"metadata":{}},{"source":["### MeanSpectrumNet\n","\n","**Check the implementation of the following baseline architecture:**\n","\n","* Compute the mean spectrum (mean over the steps dimension).\n","* Linear layer: network inputs to 128 units followed by a ReLU.\n","* Linear layer: 128 to 128 units followed by a ReLU.\n","* Linear layer: 128 to the network output."],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["class MeanSpectrumNet(torch.nn.Module):\n","    def __init__(self, inputs=17, outputs=1):\n","        super().__init__()\n","\n","        self.net = torch.nn.Sequential(\n","            torch.nn.Linear(inputs, 128),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(128, 64),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(64, outputs),\n","        )\n","        \n","    def forward(self, x):\n","        # x shape: (samples, steps, inputs)\n","        # compute the mean over all steps\n","        x = torch.mean(x, axis=1)\n","        return self.net(x)\n","\n","net = MeanSpectrumNet()\n","print(net)"],"outputs":[],"metadata":{}},{"source":["### ConvNet\n","\n","**Complete the implementation of the following architecture:**\n","\n","Convolution over the steps, using frequencies as channels:\n","* 1D-convolution: network inputs to 32 channels, kernel size 3, ReLU.\n","* Average pooling: 2.\n","* 1D-convolution: 32 to 64 channels, kernel size 3, ReLU.\n","* Average pooling: 2.\n","* 1D-convolution: 64 to 128 channels, kernel size 3, ReLU.\n","* `AdaptiveAvgPool1d(1)`: Compute the mean for each channel over all steps.\n","* Flatten.\n","* Linear layer: 128 to the network output."],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["class ConvNet(torch.nn.Module):\n","    def __init__(self, inputs=1, outputs=1):\n","        super().__init__()\n","\n","        self.net = torch.nn.Sequential(\n","            # TODO add the convolutional and pooling layers\n","            \n","            torch.nn.AdaptiveAvgPool1d(1),\n","            torch.nn.Flatten(),\n","            torch.nn.Linear(128, outputs),\n","        )\n","        \n","    def forward(self, x):\n","        # x shape: (samples, steps, inputs)\n","        # swap the steps and inputs dimensions, so we can convolve over\n","        # the steps use the frequencies as channels\n","        x = x.transpose(2, 1)\n","        return self.net(x)\n","\n","net = ConvNet()"],"outputs":[],"metadata":{}},{"source":["### RNNNet\n","\n","**Check the implementation of the following architecture:**\n","\n","* RNN: network input to 128 hidden units.\n","* Use the final hidden state from the RNN.\n","* Linear layer: 128 to 128 units followed by a ReLU.\n","* Linear layer: 128 to the network output."],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["class RNNNet(torch.nn.Module):\n","    def __init__(self, inputs=17, outputs=1):\n","        super().__init__()\n","\n","        self.rnn = RNN(inputs, 128)\n","        self.linear = torch.nn.Sequential(\n","            torch.nn.Linear(128, 128),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(128, outputs)\n","        )\n","        \n","    def forward(self, x):\n","        # x shape: (samples, steps, inputs)\n","        out, (h,) = self.rnn(x)\n","        \n","        # use the final RNN hidden state as input\n","        # for the fully connected part\n","        return self.linear(h)\n","\n","net = RNNNet()\n","print(net)"],"outputs":[],"metadata":{}},{"source":["### LSTMNet\n","\n","**Implement the following architecture:** (see RNNNet for an example)\n","\n","* LSTM: network input to 128 hidden units.\n","* Use the final hidden state from the LSTM.\n","* Linear layer: 128 to 128 units followed by a ReLU.\n","* Linear layer: 128 to the network output."],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["class LSTMNet(torch.nn.Module):\n","    def __init__(self, inputs=17, outputs=1):\n","        super().__init__()\n","\n","        # TODO define the LSTM layer and the linear network\n","        #      (see RNNNet for an example)\n","        \n","    def forward(self, x):\n","        # x shape: (samples, steps, inputs)\n","        # TODO call the LSTM layer and then the linear network\n","        #      (see RNNNet for an example)\n","\n","net = LSTMNet()\n","print(net)"],"outputs":[],"metadata":{}},{"source":["### TorchLSTMNet\n","\n","Implementing your own modules can be fun and good learning experience, but it is not always the most efficient solution. The built-in [LSTM implementation](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM) from PyTorch is much faster than our own version.\n","\n","**Implement a network similar to LSTMNet using the PyTorch torch.nn.LSTM module.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["class TorchLSTMNet(torch.nn.Module):\n","    # TODO make this identical to LSTMNet, but use torch.nn.LSTM\n","    #      instead of the LSTM layer you implemented yourself\n","\n","net = TorchLSTMNet()\n","print(net)"],"outputs":[],"metadata":{}},{"source":["## 3.10 Experiments\n","\n","**Train the models on the chunked dataset.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["train(MeanSpectrumNet(), chunked_loaders, epochs=100, lr=0.01)"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["train(FullyConnectedNet(40 * 17), chunked_loaders, epochs=25, lr=0.01)"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["train(ConvNet(17), chunked_loaders, epochs=50, lr=0.01)"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["train(RNNNet(17), chunked_loaders, epochs=20, lr=0.01)"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["train(LSTMNet(17), chunked_loaders, epochs=20, lr=0.01)"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["train(TorchLSTMNet(17), chunked_loaders, epochs=20, lr=0.01)"],"outputs":[],"metadata":{}},{"source":["## 3.11 Discussion"],"cell_type":"markdown","metadata":{}},{"source":["**Briefly discuss and compare the performance of the models in your experiments. Which worked best and why?**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here.\n","\n","* *MeanSpectrumNet*:\n","* *FullyConnectedNet*:\n","* *ConvNet*:\n","* *RNNNet*:\n","* *(Torch)LSTMNet*:"],"cell_type":"markdown","metadata":{}},{"source":["**Why do some of those models generalize better than others?**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here."],"cell_type":"markdown","metadata":{}},{"source":["**How does your LSTM implementation compare with the PyTorch implementation?**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here."],"cell_type":"markdown","metadata":{}},{"source":["**Your RNN model probably didn't work well. Why is that model more difficult to train than the LSTM?**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here."],"cell_type":"markdown","metadata":{}},{"source":["**The convolutional network and the LSTM in these experiments both work on the time dimension. What are the advantages and disadvantages of each approach?**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here."],"cell_type":"markdown","metadata":{}},{"source":["**For reasons of speed, we used a fairly small window of 40 time steps. Suppose that we would make this window much larger. How do you think this would affect each model?**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here."],"cell_type":"markdown","metadata":{}},{"source":["**One of the difficulties with recurrent networks is that inputs from early steps are quite far away from the final result. How would you suggest to reduce that problem?**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here."],"cell_type":"markdown","metadata":{}},{"source":["## 3.12 Data augmentation\n","\n","Especially if your dataset is small, data augmentation can help to improve the performance of your network.\n","\n","We have an easy way to add some data augmentation to the ECG dataset. In our preprocessing, we divided each recording into small chunks of 40 time steps, which we then reused in every epoch. We can add more variation to the training set by creating chunks at random positions.\n","\n","The [DataLoader](https://pytorch.org/docs/stable/data.html) class in PyTorch has a `collate_fn` parameter to which we can pass a function. This function is called for each minibatch in each epoch. We will use this to extract a random chunk from each sample.\n","\n","The function `random_chunk_collage` takes a minibatch of samples, chooses a random offset for each sample, extracts a small chunk at that position, and then concatenates and returns the result."],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["def random_chunk_collate_fn(samples, window_size):\n","    # Take a list of tensors of (steps_i, features),\n","    # extract a random window of length window_size from each tensor,\n","    # concatenate to a tensor of shape (samples, window_size, features).\n","    x_batch = torch.empty((len(samples), window_size) + samples[0][0].shape[1:],\n","                          device=samples[0][0].device, dtype=samples[0][0].dtype)\n","    y_batch = torch.empty((len(samples),),\n","                          device=samples[0][1].device, dtype=samples[0][1].dtype)\n","    for i, (x, y) in enumerate(samples):\n","        # extract a random window\n","        offset = torch.randint(x.shape[0] - window_size, (1,))\n","        x_batch[i, :] = x[offset:offset + window_size]\n","        y_batch[i] = y\n","    return x_batch, y_batch"],"outputs":[],"metadata":{}},{"source":["We construct a new DataLoader for our training set:"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["# test to see the x and y shapes for one sample\n","random_chunk_loaders = {\n","    'train': torch.utils.data.DataLoader(data_train, shuffle=True, batch_size=128,\n","                                         collate_fn=lambda s: random_chunk_collate_fn(s, window_size=40)),\n","    'val':   chunked_loaders['val']\n","}\n","for (x, y) in random_chunk_loaders['train']:\n","    print(x.shape, y.shape)\n","    break"],"outputs":[],"metadata":{}},{"source":["Observe that the pre-chunked dataset was much larger than the new dataset with on-the-fly chunking. You might want to increase the number of training epochs a bit to make sure that the network sees a similar number of examples."],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["print('Minibatches in chunked_loader[\\'train\\']:      ', len(chunked_loaders['train']))\n","print('Minibatches in random_chunk_loaders[\\'train\\']:', len(random_chunk_loaders['train']))"],"outputs":[],"metadata":{}},{"source":["Let's see how this data augmentation method affects the performance of your networks.\n","\n","**Train the MeanSpectrumNet, FullyConnectedNet, ConvNet and TorchLSTMNet from the previous experiments on data from the `random_chunk_loaders`.**"],"cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":["train(MeanSpectrumNet(), random_chunk_loaders, epochs=100, lr=0.01)"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["train(FullyConnectedNet(40 * 17), random_chunk_loaders, epochs=100, lr=0.01)"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["train(ConvNet(17), random_chunk_loaders, epochs=50, lr=0.01)"],"outputs":[],"metadata":{}},{"execution_count":null,"cell_type":"code","source":["train(TorchLSTMNet(17), random_chunk_loaders, epochs=100, lr=0.01)"],"outputs":[],"metadata":{}},{"source":["## 3.13 Discussion"],"cell_type":"markdown","metadata":{}},{"source":["**How does the data augmentation influence the results? Can you explain this?**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here."],"cell_type":"markdown","metadata":{}},{"source":["**Why does the data augmentation affect some models more than others?**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here."],"cell_type":"markdown","metadata":{}},{"source":["**Should we also do data augmentation on the validation set? Why, or why not?**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here."],"cell_type":"markdown","metadata":{}},{"source":["**Data augmentation is often a good way to add some domain knowledge to your model. Based on your knowledge of ECGs, why is (or isn't) our augmentation method a good idea?**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here."],"cell_type":"markdown","metadata":{}},{"source":["**Give an example of another suitable augmentation method and explain why it would work for this data.**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here."],"cell_type":"markdown","metadata":{}},{"source":["**Give an example of an augmentation method that might be suitable for other data but would probably not work here. Explain why.**"],"cell_type":"markdown","metadata":{}},{"source":["TODO: Your answer here."],"cell_type":"markdown","metadata":{}},{"source":["## The end\n","\n","Well done! Please double check the instructions at the top before you submit your results."],"cell_type":"markdown","metadata":{}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","file_extension":".py","version":"3.8.2","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"}},"deepnote_notebook_id":"8f2af4fb-a00c-426b-b6a6-98ed28611f3b"}}